{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 10 17:08:18 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.119.03   Driver Version: 450.119.03   CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 206...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   53C    P8     7W /  N/A |    852MiB /  5934MiB |     17%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1091      G   /usr/lib/xorg/Xorg                306MiB |\n",
      "|    0   N/A  N/A      1510      G   /usr/bin/gnome-shell              195MiB |\n",
      "|    0   N/A  N/A      2276      G   ...AAAAAAAAA= --shared-files      118MiB |\n",
      "|    0   N/A  N/A      7070      G   ...AAAAAAAAA= --shared-files       58MiB |\n",
      "|    0   N/A  N/A      7193      G   ...AAAAAAAA== --shared-files      167MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "  print('and then re-execute this cell.')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import datetime\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 2.4.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow Version: {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/home/teamo/point_process_piplines/KITTI/object/object_training_datasets\"\n",
    "file_list = glob.glob(os.path.join(root,\"*/*.txt\"))\n",
    "cls_names = [p.split(\"/\")[7] for p in file_list]\n",
    "cls_names = np.unique(cls_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "clsname_to_index = dict((name,index) for index,name in enumerate(cls_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_clsname = dict((index,name) for name,index in clsname_to_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_shuffle = np.random.permutation(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = np.asarray(file_list)[index_shuffle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = file_list[:int(0.8*N)]\n",
    "test_list = file_list[int(0.8*N):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = list(train_list)\n",
    "test_paths = list(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = [clsname_to_index.get(p.split(\"/\")[7]) for p in train_paths]\n",
    "test_labels = [clsname_to_index.get(p.split(\"/\")[7]) for p in test_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = tf.data.Dataset.from_tensor_slices((train_paths,train_labels))\n",
    "test_datasets = tf.data.Dataset.from_tensor_slices((test_paths,test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_fun(path,label):\n",
    "  # 读取点云文件\n",
    "  point_cloud_path = path.numpy()\n",
    "  point_cloud_path = point_cloud_path.decode()\n",
    "  point_cloud = pd.read_csv(point_cloud_path)\n",
    "  point_cloud = np.array(point_cloud.iloc[:,0:6])\n",
    "\n",
    "  # 归一化\n",
    "  point_cloud[:,0:3] = point_cloud[:,0:3] - np.expand_dims(np.mean(point_cloud[:,0:3],0),0)\n",
    "  dist = np.max(np.sqrt(np.sum(point_cloud[:,0:3]**2,axis=1)),0)\n",
    "  if(dist > 0.0001):\n",
    "    point_cloud[:,0:3] = point_cloud[:,0:3]/dist\n",
    "\n",
    "  # 绕Z轴旋转随机角度\n",
    "  theta = np.random.uniform(0,np.pi*2)\n",
    "  rotation_matrix = np.array([[np.cos(theta), -np.sin(theta)],[np.sin(theta), np.cos(theta)]])\n",
    "  point_cloud[:,[0,1]] = point_cloud[:,[0,1]].dot(rotation_matrix)\n",
    "  point_cloud[:,[3,4]] = point_cloud[:,[3,4]].dot(rotation_matrix)\n",
    "\n",
    "  point_cloud = tf.convert_to_tensor(point_cloud,dtype=tf.float64)\n",
    "\n",
    "  # 添加噪声\n",
    "  point_cloud += tf.random.uniform(point_cloud.shape, -0.005, 0.005, dtype=tf.float64)\n",
    "  # 随机乱序\n",
    "  point_cloud = tf.random.shuffle(point_cloud)\n",
    "\n",
    "  label = tf.cast(label,dtype=tf.int64)\n",
    "  return point_cloud,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train(x,y):\n",
    "    x, y = tf.py_function(load_train_fun, inp=[x, y], Tout=[tf.float64, tf.int64])\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_fun(path,label):\n",
    "  # 读取点云文件\n",
    "  point_cloud_path = path.numpy()\n",
    "  point_cloud_path = point_cloud_path.decode()\n",
    "  point_cloud = pd.read_csv(point_cloud_path)\n",
    "  point_cloud = np.array(point_cloud.iloc[:,0:6])\n",
    "\n",
    "  # 归一化\n",
    "  point_cloud[:,0:3] = point_cloud[:,0:3] - np.expand_dims(np.mean(point_cloud[:,0:3],0),0)\n",
    "  dist = np.max(np.sqrt(np.sum(point_cloud[:,0:3]**2,axis=1)),0)\n",
    "  if(dist > 0.0001):\n",
    "    point_cloud[:,0:3] = point_cloud[:,0:3]/dist\n",
    "\n",
    "  point_cloud = tf.convert_to_tensor(point_cloud,dtype=tf.float64)\n",
    "  label = tf.cast(label,dtype=tf.int64)\n",
    "  return point_cloud,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test(x,y):\n",
    "    x, y = tf.py_function(load_test_fun, inp=[x, y], Tout=[tf.float64, tf.int64])\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = train_datasets.shuffle(len(train_paths))\n",
    "test_datasets = test_datasets.shuffle(len(test_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = train_datasets.map(load_train)\n",
    "test_datasets = test_datasets.map(load_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_POINTS = 64\n",
    "NUM_CLASSES = 40\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = train_datasets.batch(BATCH_SIZE)\n",
    "test_datasets = test_datasets.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn(x, filters):\n",
    "    x = layers.Conv1D(filters, kernel_size=1, padding=\"valid\")(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "    return layers.Activation(\"relu\")(x)\n",
    "\n",
    "\n",
    "def dense_bn(x, filters):\n",
    "    x = layers.Dense(filters)(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "    return layers.Activation(\"relu\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用来保证矩阵的秩为1\n",
    "class OrthogonalRegularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, num_features, l2reg=0.001):\n",
    "        self.num_features = num_features\n",
    "        self.l2reg = l2reg\n",
    "        self.eye = tf.eye(num_features)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = tf.reshape(x, (-1, self.num_features, self.num_features))\n",
    "        xxt = tf.tensordot(x, x, axes=(2, 2))\n",
    "        xxt = tf.reshape(xxt, (-1, self.num_features, self.num_features))\n",
    "        return tf.reduce_sum(self.l2reg * tf.square(xxt - self.eye))\n",
    "\n",
    "    def get_config(self):\n",
    "      return {'num_features': int(self.num_features), 'l2reg': float(self.l2reg)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tnet(inputs, num_features):\n",
    "\n",
    "    # Initalise bias as the indentity matrix\n",
    "    bias = keras.initializers.Constant(np.eye(num_features).flatten())\n",
    "    reg = OrthogonalRegularizer(num_features)\n",
    "  \n",
    "    x = conv_bn(inputs, 64)\n",
    "    x = conv_bn(x, 128)\n",
    "    x = conv_bn(x, 1024)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = dense_bn(x, 512)\n",
    "    x = dense_bn(x, 256)\n",
    "    x = layers.Dense(\n",
    "        num_features * num_features,\n",
    "        kernel_initializer=\"zeros\",\n",
    "        bias_initializer=bias,\n",
    "        activity_regularizer=reg,\n",
    "    )(x)\n",
    "    feat_T = layers.Reshape((num_features, num_features))(x)\n",
    "    # Apply affine transformation to input features\n",
    "    return layers.Dot(axes=(2, 1))([inputs, feat_T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"pointnet\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 64, 6)]           0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 64, 64)            448       \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 64, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 64, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 64, 64)            4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 64, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 64, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 64, 64)            4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 64, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 64, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 64, 128)           8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 64, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 64, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 64, 1024)          132096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 64, 1024)          4096      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 64, 1024)          0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 40)                10280     \n",
      "=================================================================\n",
      "Total params: 824,040\n",
      "Trainable params: 819,816\n",
      "Non-trainable params: 4,224\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(NUM_POINTS, 6))\n",
    "\n",
    "#x = tnet(inputs, 3)\n",
    "x = conv_bn(inputs, 64)\n",
    "x = conv_bn(x, 64)\n",
    "#x = tnet(x, 64)\n",
    "x = conv_bn(x, 64)\n",
    "x = conv_bn(x, 128)\n",
    "x = conv_bn(x, 1024)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = dense_bn(x, 512)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = dense_bn(x, 256)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"pointnet\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(\"logs\",datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "tenserboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n",
      "2671/2671 [==============================] - 235s 88ms/step - loss: 0.7511 - sparse_categorical_accuracy: 0.7209 - val_loss: 7.4684 - val_sparse_categorical_accuracy: 0.4103\n",
      "Epoch 2/18\n",
      "2671/2671 [==============================] - 231s 87ms/step - loss: 0.4562 - sparse_categorical_accuracy: 0.8300 - val_loss: 2.3178 - val_sparse_categorical_accuracy: 0.6461\n",
      "Epoch 3/18\n",
      "2671/2671 [==============================] - 230s 86ms/step - loss: 0.3757 - sparse_categorical_accuracy: 0.8634 - val_loss: 1.0613 - val_sparse_categorical_accuracy: 0.8496\n",
      "Epoch 4/18\n",
      "2671/2671 [==============================] - 233s 87ms/step - loss: 0.3293 - sparse_categorical_accuracy: 0.8784 - val_loss: 0.8850 - val_sparse_categorical_accuracy: 0.8331\n",
      "Epoch 5/18\n",
      "2671/2671 [==============================] - 231s 87ms/step - loss: 0.2989 - sparse_categorical_accuracy: 0.8908 - val_loss: 2.2215 - val_sparse_categorical_accuracy: 0.7191\n",
      "Epoch 6/18\n",
      "2671/2671 [==============================] - 230s 86ms/step - loss: 0.2778 - sparse_categorical_accuracy: 0.8981 - val_loss: 7.4006 - val_sparse_categorical_accuracy: 0.4778\n",
      "Epoch 7/18\n",
      "2671/2671 [==============================] - 230s 86ms/step - loss: 0.2530 - sparse_categorical_accuracy: 0.9090 - val_loss: 2.5230 - val_sparse_categorical_accuracy: 0.6932\n",
      "Epoch 8/18\n",
      "2671/2671 [==============================] - 229s 86ms/step - loss: 0.2273 - sparse_categorical_accuracy: 0.9164 - val_loss: 2.4209 - val_sparse_categorical_accuracy: 0.7389\n",
      "Epoch 9/18\n",
      "2671/2671 [==============================] - 230s 86ms/step - loss: 0.1999 - sparse_categorical_accuracy: 0.9276 - val_loss: 4.7786 - val_sparse_categorical_accuracy: 0.5631\n",
      "Epoch 10/18\n",
      "2671/2671 [==============================] - 229s 86ms/step - loss: 0.1967 - sparse_categorical_accuracy: 0.9268 - val_loss: 1.9314 - val_sparse_categorical_accuracy: 0.7700\n",
      "Epoch 11/18\n",
      "2671/2671 [==============================] - 231s 86ms/step - loss: 0.1890 - sparse_categorical_accuracy: 0.9317 - val_loss: 1.2797 - val_sparse_categorical_accuracy: 0.8098\n",
      "Epoch 12/18\n",
      "2671/2671 [==============================] - 229s 86ms/step - loss: 0.1669 - sparse_categorical_accuracy: 0.9403 - val_loss: 2.2845 - val_sparse_categorical_accuracy: 0.7596\n",
      "Epoch 13/18\n",
      "2671/2671 [==============================] - 228s 85ms/step - loss: 0.1678 - sparse_categorical_accuracy: 0.9391 - val_loss: 1.6336 - val_sparse_categorical_accuracy: 0.8041\n",
      "Epoch 14/18\n",
      "2671/2671 [==============================] - 229s 86ms/step - loss: 0.1700 - sparse_categorical_accuracy: 0.9389 - val_loss: 1.2798 - val_sparse_categorical_accuracy: 0.8599\n",
      "Epoch 15/18\n",
      "2671/2671 [==============================] - 229s 86ms/step - loss: 0.1502 - sparse_categorical_accuracy: 0.9448 - val_loss: 2.7771 - val_sparse_categorical_accuracy: 0.7402\n",
      "Epoch 16/18\n",
      "2671/2671 [==============================] - 228s 85ms/step - loss: 0.1373 - sparse_categorical_accuracy: 0.9498 - val_loss: 9.1541 - val_sparse_categorical_accuracy: 0.3986\n",
      "Epoch 17/18\n",
      "1348/2671 [==============>...............] - ETA: 1:33 - loss: 0.1460 - sparse_categorical_accuracy: 0.9456"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-4e42b0de09d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_datasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_datasets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtenserboard_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"sparse_categorical_accuracy\"],\n",
    ")\n",
    "\n",
    "history = model.fit(train_datasets, epochs=14, validation_data=test_datasets,callbacks=[tenserboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"pointnet_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "962b00edaefde94591e29a293936598abdbbd5e5bc848f9b359e207bb81234a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
